{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.機械学習 プロジェクト全体像\n",
    "機械学習は反復型のプロセス である。手順は大きく下記の手順。本講座ではビジネス視点はあまり扱わずに技術よりの視点でそれぞれを解説します。\n",
    "\n",
    "プロジェクトスコープ決定  \n",
    "データエンジニアリング  \n",
    "モデル開発  \n",
    "モデルの運用    \n",
    "ビジネス分析  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プロジェクトスコープの決定\n",
    "業務改善のためのAIか新規ビジネスのためのAIかをまずは決定する必要がある。\n",
    "\n",
    "\n",
    "### 業務改善のためのAIか新規ビジネスのための AI か\n",
    "\n",
    "- 業務改善における AI  \n",
    "長期的に利益を得る。すでに AI を使用・活用する人、モノが存在している。  \n",
    "AI の導入により、どのくらいコストが削減できたのか、効率化ができたのかなどが主な KPI となる。\n",
    "\n",
    "- 新規ビジネスにおける AI\n",
    "新たに顧客や AI を使用する人、モノを見つける必要がある。  \n",
    "AI を導入ビジネスとして売上高・利益率:収益性を評価。売上高と利益の割合を計測する必要がる。\n",
    "\n",
    "### 機械学習とソフトウェア導入の違い\n",
    "\n",
    "機械学習→既存のデータからデータのパターンを学習、未知のデータから予測  \n",
    "各キーワードの説明  \n",
    "・データがあって、使用可能   \n",
    "・パターンがないと予測できない、株のAIがないのはパターンがないから  \n",
    "・一般的なソフトウェアと違い、学習力があるのがAI  \n",
    "・未知のデータと学習データのパターンの共有  \n",
    "・予測可能な問題であること  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習システムに求められる要件\n",
    "信頼性・拡張性・保守性・適応性 \n",
    "\n",
    "\n",
    "### 【補足】研究と実務の違い\n",
    "研究では９割がアルゴリズムを調べる\n",
    "現場はアルゴリズムにかける時間は３割程度、データ収集や前処理に時間をかける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データエンジニアリング\n",
    "\n",
    "ETL プロセス\n",
    "データの収集・処理・蓄積これらが行われる基盤があることが AI プロジェクトを成功させるうえで重要\n",
    "\n",
    "### データの収集\n",
    "データの発生箇所は多種多様化している。機械学習のワークロードでは特に様々な場所からデータを収集することが多い。\n",
    "例えば、飲食店の売上予測をするAIを作りたい時、アンケートDB からアンケートデータや、PoSレジの売上データ、気象庁の天気データなどが売上を予測するうえで重要なデータとなる可能性が高い。  \n",
    "このように一般的なデータを扱うシステムと異なり、いくつものDBやストレージを横断してデータを収集する。  \n",
    "形式も形も違うデータをまずは一箇所に集める。収集先をデータレイクという。\n",
    "\n",
    "### データの処理\n",
    "次にデータ処理を行う。\n",
    "機械学習はデータから関係性を見つけだすために数値計算を行う。そのためにはまずはテーブルデータ化することが必要。 \n",
    "このための処理を行う。ビックデータを扱うため、Spark などの並列処理技術を使用することが多い。\n",
    "\n",
    "### データの蓄積\n",
    "処理が終わったデータを蓄積する。このときに列思考型のデータとして保存することが特徴。  \n",
    "保存場所をDWHという。列思考型のDBのことを指すことが多い。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.AI プロジェクトの開発プロセス\n",
    "ここまで説明した、企画→分析のためのデータ基盤があり、そこから AI の開発に進む。データ基盤なしで開発に進む企業も多いが、その後の運用を考えたときにデータ基盤があったほうが AI 導入におけるビジネス成功率が高まる。\n",
    "\n",
    "次に AI の開発手順について確認する。以下のような手順で開発を行う。  \n",
    "環境構築・データの収集・前処理・モデル構築・検証。運用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル開発・検証の全体的な流れ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの前処理\n",
    "AI の開発において最も時間のかかる、フローがデータの前処理です。\n",
    "ETL の処理においてはテーブル化を行うための処理をしました。\n",
    "こちらでは下記のような前処理を行います。\n",
    "\n",
    "- スケーリング  \n",
    "- 欠損値処理  \n",
    "- 数値化  \n",
    "\n",
    "### 構築\n",
    "前処理を行い、AI の構築を行います。\n",
    "実際にモデルを作成するうえでの代表的な考慮事項としてアルゴリズムとハイパーパラメータについてお伝えします。\n",
    "アルゴリズム：計算方法です。代表的な手法としてDLや重回帰分析、SVM、決定木などがあります。複雑なアルゴリズムほど、難しい予測が可能になりますが逆になぜその予測となったとのかが説明しにくくなります。  \n",
    "ハイパーパラメータ：決定したアルゴリズムで計算を行う際に人間側で調整を行うパラメータのことです。例えば決定木という手法であれば分岐を何回行うのか、深さをどのくらいにするのかなどといったハイパーパラメータがあります。  \n",
    "\n",
    "最適なアルゴリズム・ハイパーパラメータを決定することによりより精度の高いモデルを作成することが可能です。\n",
    "\n",
    "### AI の評価（分類・回帰）\n",
    "次に AI の評価についてお話します。一般的な指標として分類であれば当てはまり率を表す成果率（ACC）や回帰であれば、予測と実際の値の誤差をみて評価をすることが可能です。ですがデータが不均衡で有った場合などでもAIを評価出来るよう代表的な評価指標を紹介します。\n",
    "\n",
    "### 分類の評価指標\n",
    "\n",
    "#### 混合行列\n",
    "分類の評価方法\n",
    "分類において、学習済みモデルを評価する指標には様々なものがありますが、その中でも代表的なものに下記の 4 つが挙げられます。\n",
    "\n",
    "- 正解率\n",
    "- 適合率\n",
    "- 再現率\n",
    "- F 値\n",
    "\n",
    "分類の評価方法では、ここまで Accuracy（正解率）を使用してきました。しかし、実問題では Accuracy だけを用いて評価を行っていると危険性がある場合があります。本節では、分類で使用されるいくつかの評価方法を紹介していきます。\n",
    "\n",
    "例えば、ラベルの種類が 2 種類しかないような二値分類の問題設定でデータセットの中身の 99% がラベル 0、そして残りの 1% がラベル 1 というような割合の場合に Accuracy を最大化するためにどうするでしょうか。 全てをラベル 0 と答え、ラベル 1 に対しては全く分類しないという選択を取ることが考えられます。\n",
    "\n",
    "なぜなら、そのような選択を取ることにより、Accuracy は必然的に 99% になると言えるためです。このような結果が望ましい問題設定もあれば、望ましくない問題設定もあることが考えられます。\n",
    "\n",
    "ここではがん診断の例を用いて Accuracy 以外のモデルの評価指標について確認しましょう。\n",
    "\n",
    "人数\n",
    "全体\t260\n",
    "健康な人\t200\n",
    "がん患者\t60\n",
    "\n",
    "\n",
    "上記は実測値です。Precision など Accuracy 以外の指標を理解するためには、この実測値（実際の状態）と予測値（診察結果）の関係性を理解することが重要です。この関係性を理解するために混同行列 (Confusion Matrix) と呼ばれる以下の表を使用します。\n",
    "\n",
    "\n",
    "表の見方ですが、診察結果（縦の方向）と実際の状態（横方向）の関係を表したものです。それぞれの値には名前が付いており、下記のように表記され呼ばれます。\n",
    "  \n",
    "TP (True Positive、真陽性)：予測値を正例として、その予測が正しい場合の数  \n",
    "FP (False Positive、偽陽性)：予測値を正例として、その予測が誤りの場合の数  \n",
    "TN (True Negative、真陰性)：予測値を負例として、その予測が正しい場合の数  \n",
    "FN (False Negative、偽陰性)：予測値を負例として、その予測が誤りの場合の数  \n",
    "こちらの混合行列を軸に各指標を確認していきます。今回のがん診断では、正例をがん患者、負例を健康な患者として話を進めていきます。\n",
    "\n",
    "True/False は予測したものが正しいか誤りか、Positive/Negative は予測値を正例としたか負例としたかと考えると組み合わせで理解しやすいです。  \n",
    "\n",
    "- Accuracy（正解率）  \n",
    "全ての値を足し合わせて、実際にどれだけ合っているのか測るのが、Accuracy です。Accuracy は分類の精度を確認するための指標として最も一般的なものです。 \n",
    "\n",
    "- Precision \n",
    "混同行列を縦方向に捉えます。正例（がん）と予測したもののうち、本当に正しく診断できた数の割合を表します。誤診を少なくしたい場合は Precision を重視することになります。\n",
    "\n",
    "- Recall \n",
    "混同行列を横方向に捉えます。実際の状態が正例（がん）のうち、どの程度正例であると予測できた数の割合です。誤診は許容するが、正例の見逃しを避けたい場合に Recall を重視することになります。\n",
    "\n",
    "- F1 score（F 値）\n",
    "Precision と Recall は互いにトレードオフの関係にあります。どちらかの値を上げようとすると、もう一方の値が下がることになります。つまり、どちらかの指標を考慮しなければ、もう片方を 1 に近づけることができるので指標として少し極端な評価指標ということになります。\n",
    "\n",
    "そこで、Precision と Recall の両者のバランスを取るために調和平均で計算される指標が F1-score です。\n",
    "\n",
    "これらの指標は、取り組みたい問題設定によってどの評価指標を選択するかは異なります。問題設定合わせて重視するポイントをしっかり考慮し、最適な指標を選択しましょう。\n",
    "\n",
    "\n",
    "\n",
    "#### ROC/OCR\n",
    "ROC 曲線\n",
    "分類の指標としてよく用いられるものには ROC 曲線もあります。\n",
    "\n",
    "ROC 曲線は2つの値から構成されます。\n",
    "\n",
    "True Positive Rate(真陽性率）：\n",
    "False Positive Rate(偽陽性率）：\n",
    "横軸に FPR を, 縦軸に TPR をとり、分類の閾値を変化させていった時の各値をプロットした点を結ぶと ROC 曲線を描くことができます。\n",
    "![02](img/02/04.png)\n",
    "2 値分類の場合、ロジスティック回帰などではデフォルトで分類の閾値が 0.5 と設定されています。これは、例えばモデルがあるサンプルについてクラス 1 に属する確率を 0.6 と出力した時に、0.5 を上回るためそのサンプルはクラス 1 と分類する、ということです。閾値を仮に 0.3 と定めれば、この例については予測確率は閾値を下回るため、クラス 0 と分類されることになります。\n",
    "\n",
    "このように、分類の閾値を調整することで分類結果は変化し、モデルの正例の検出力や、過剰検知の程度などが変化します。分類の閾値を、課題に応じて最適に調整を行いたい場合に、ROC 曲線の情報は参考になります。\n",
    "\n",
    "AUC\n",
    "AUC (Area of Under a Curve）は曲線の下のエリアを指す用語です。\n",
    "基本的に機械学習領域では ROC/AUC として、Area of Under an ROC Curveを指すことが多いです。\n",
    "\n",
    "今回は ROC 曲線下の大きさを表します。すべてのサンプルを正しく予測できていた場合、ROC 曲線は FPR 0 で TPR 1 となるため、AUC は 1 となります。一方で、当てずっぽうに予測を行う場合、2 値分類の ROC 曲線は (FPR, TPR) = (0, 0) の点と (1, 1) の点を結んだ傾き 1 の直線となるため、AUC は 0.5 となります。\n",
    "\n",
    "このように、良い分類ができた時には 1 に近づく性質があり、AUC の値もモデルの評価に使用することができます。\n",
    "\n",
    "\n",
    "\n",
    "縦軸が True Positive Rate、横軸が False Positive Rate を表してます。\n",
    "\n",
    "ROC 曲線は青色のエリアが大きいほどよいです。ROC 曲線の最低ラインは曲線が直線となる時です。その時分類は 50% の精度で適当に分類しているのと同じことになるからです。\n",
    "### 回帰の評価指標\n",
    "回帰分析では、モデルの予測の精度を評価するためのいくつかの指標があります。以下では、回帰モデルの評価によく使われる3つの主要な指標、決定係数、平均二乗誤差、平均絶対値誤差について説明します。\n",
    "\n",
    "#### 決定係数（R^2）\n",
    "決定係数は、モデルがデータの変動をどれだけ説明しているかを示す指標です。値は0から1の範囲で、1に近いほどモデルの予測がデータの変動をよく説明していることを意味します。\n",
    "\n",
    "例えば、決定係数が0.8の場合、モデルはデータの80%の変動を説明しています。ただし、高い決定係数が必ずしも良いモデルであるとは限らないことに注意が必要です。\n",
    "\n",
    "#### 平均二乗誤差（MSE）\n",
    "平均二乗誤差は、モデルの予測値と実際の値との差の平均を示す指標です。この誤差は2乗されているため、大きな誤差があるとその影響が大きくなります。\n",
    "\n",
    "平均二乗誤差が小さいほど、モデルの予測が実際の値に近いことを意味します。この指標は、外れ値の影響を受けやすいため、データの分布に応じて適切に評価する必要があります。\n",
    "\n",
    "#### 平均絶対値誤差（MAE）\n",
    "平均絶対値誤差は、モデルの予測値と実際の値との差の絶対値の平均を示す指標です。この指標は、2乗誤差の影響を受けないため、外れ値の影響を受けにくいとされています。\n",
    "\n",
    "平均絶対値誤差も小さいほど、モデルの予測が実際の値に近いことを意味します。この指標は、モデルの予測の精度を評価する際によく使用されます。\n",
    "\n",
    "これらの指標を組み合わせて使用することで、回帰モデルの性能をより総合的に評価することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【おまけ】生成 AI の評価\n",
    "Chat GPT　を含む生成 AI のモデルの評価についてです。  \n",
    "生成AIの仕組みとして単語を多次元空間にプロットし、その位置空間情報に基づいて回答を生成します。　　　  \n",
    "事前に質問と回答のペアを用意しバッチ処理で推論と答え合わせを行うことにより、生成 AI モデルの評価を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【補足】機械学習のニーズ\n",
    "難しいことをしようとしなくていい\n",
    "\n",
    "https://blog.jcharistech.com/2019/07/23/the-data-science-pyramid-hierarchy-of-needs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの運用\n",
    "モデルの運用は大きく、リアルタイムorバッチ推論、構築・デプロイの環境や再学習のパイプライン、監視などがある。\n",
    "AI を導入するにあたってバッチ推論かリアルタイム推論のユースケースなのかを判断する\n",
    "\n",
    "\n",
    "### バッチ推論とは\n",
    "\n",
    "集に 1 回など決まったタイミングで一括で推論を行う。  \n",
    "ある程度、見積もりが立てて運用することが可能\n",
    "\n",
    "### リアルタイム推論とは\n",
    "\n",
    "データの送信とともに推論を行い予測を行う。\n",
    "一時的な需要の増加にも可用性を維持出来るようなアーキテクチャを考慮する必要がある。\n",
    "\n",
    "次に、構築・運用を行う環境について確認する。大きく、オンプレミスかクラウドかまたは両方のハイブリッドを選択出来る。\n",
    "\n",
    "### オンプレミスでのAI構築・運用\n",
    "\n",
    "自社内で AI の開発・運用を行う。  \n",
    "設備投資が必要だが、よりセキュアにAI構築・運用を行うことが可能。既存の技術を使用することが出来る。\n",
    "サーバー管理や環境構築から運用までをすべて自社で行う。\n",
    "\n",
    "### クラウドでのAI 構築・運用\n",
    "\n",
    "事前の設備投資は必要ない、開発しながら求められるスペックなどを検討出来る。スケールアウトなども用意\n",
    "デフォルトだとクラウドストレージへのデータのアップロードはインターネットを通るため、ネットワーク整備などが必要。データのガバナンスなどの確認も必要。  \n",
    "開発者はより AI 開発に焦点を置きながら開発を行うことが可能。  \n",
    "\n",
    "最後に監視。\n",
    "AI の精度を見ることももちろん重要だが、データの変化を監視することも重要。\n",
    "データの変化によって、モデルの精度が落ちることをデータドリフトという。  \n",
    "モデルの運用状況の監視も重要だが、データドリフトの監視も重要。データの周期性などを理解することによって再学習のタイミングを決めることも可能。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラウドでのAI の活用について実際に触って体験してみる。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
